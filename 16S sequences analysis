# Analysis of 16S Miseq Data
raw sequence data stored on HPCC
/mnt/research/ShadeLab/Sequence/raw_sequence/AppleReplant/20171113_16S-V4_PE/

soil pore 16S DNA:  20 total files


Moved Kravchenko sequences to working space for analysis
ShadeLab/WorkingSpace/Grady/Kravchenko



# Part I: Clustering

## Merge Paired End Reads
Here we are using the RDPs usearch64, and copied an executable to this directory.  All commands start with "./usearch64" instead of "usearch"

usearch v10.0.240_i86linux64, 16.3Gb RAM, 4 cores
(C) Copyright 2013-17 Robert C. Edgar, all rights reserved.
http://drive5.com/usearch


```
#decompress the reads
gunzip *.gz

mkdir mergedfastq
#rename files to remove -
rename "-" "" *fastq


./usearch64 -fastq_mergepairs *R1*.fastq -relabel @ -fastq_maxdiffs 10 -fastqout mergedfastq/merged.fq -fastq_merge_maxee 1.0 -fastq_minmergelen 250 -fastq_maxmergelen 300

# call executable usearch64 from within this folder.
# merge pairs with R1 as the name.  Relabel with everything before the _ (samples will be named K11, K12 etc.) Allow 10 max differences in overlap region. put output file into the mergedfasq directory, named merged.fq. merged length between 250 & 300
```

### Output

```
Totals:
148325  Pairs (148.3k)
115117  Merged (115.1k, 77.61%)
40952  Alignments with zero diffs (27.61%)
32366  Too many diffs (> 10) (21.82%)
793  No alignment found (0.53%)
0  Alignment too short (< 16) (0.00%)
47  Merged too short (< 250)
2  Merged too long (> 300)
0  Exp.errs. too high (max=1.0) (0.00%)
67  Staggered pairs (0.05%) merged & trimmed
246.98  Mean alignment length
253.02  Mean merged length
0.72  Mean fwd expected errors
1.35  Mean rev expected errors
0.20  Mean merged expected errors
```

## Dereplicate sequences
```
./usearch64 -fastx_uniques mergedfastq/merged.fq -fastqout mergedfastq/uniques_combined_merged.fastq -sizeout
```
###Output
00:01 111Mb   100.0% Reading mergedfastq/merged.fq
00:01 293Mb   100.0% DF
00:01 295Mb  115117 seqs, 48603 uniques, 36256 singletons (74.6%)
00:01 295Mb  Min size 1, median 1, max 5012, avg 2.37
00:02 288Mb   100.0% Writing mergedfastq/uniques_combined_merged.fastq


## Remove Singeltons
```
./usearch64 -sortbysize mergedfastq/uniques_combined_merged.fastq -fastqout mergedfastq/nosigs_uniques_combined_merged.fastq -minsize 2
```
### Output
00:00 73Mb    100.0% Reading mergedfastq/uniques_combined_merged.fastq
00:00 39Mb   Getting sizes
00:00 39Mb   Sorting 12347 sequences
00:00 39Mb    100.0% Writing output


## Precluster Sequences
```
./usearch64 -cluster_fast mergedfastq/nosigs_uniques_combined_merged.fastq -centroids_fastq mergedfastq/denoised_nosigs_uniques_combined_merged.fastq -id 0.9 -maxdiffs 5 -abskew 10 -sizein -sizeout -sort size
```
### Output
Seqs  12347 (12.3k)
Clusters  5586
Max size  10973 (11.0k)
Avg size  14.1
Min size  2
Singletons  0, 0.0% of seqs, 0.0% of clusters
Max mem  257Mb
Time  1.00s
Throughput  12.3k seqs/sec.

## Reference-based OTU picking using Silva database


```
./usearch64 -usearch_global mergedfastq/denoised_nosigs_uniques_combined_merged.fastq -id 0.97 -db /mnt/research/ShadeLab/WorkingSpace/Silva_v119_referencefiles/Silva_119_rep_set97.fna  -strand plus -uc mergedfastq/ref_seqs.uc -dbmatched mergedfastq/closed_reference.fasta -notmatchedfq mergedfastq/failed_closed.fq
```
Closed reference OTU picking:
Pick OTUs based on the Silva database in the Shade Lab working space.
Produce some output files - ref_seqs.uc (pre-clustered), closed_reference.fasta will be the matched ones, and failed_closed.fq will be used in de novo OTU picking

## De novo OTU picking

```
#sort by size
./usearch64 -sortbysize mergedfastq/failed_closed.fq -fastaout mergedfastq/sorted_failed_closed.fq

#cluster de novo
./usearch64 -cluster_otus mergedfastq/sorted_failed_closed.fq -minsize 2 -otus mergedfastq/denovo_otus.fasta -relabel OTU_dn_ -uparseout denovo_out.up
```
### Output
00:02 56Mb    100.0% 970 OTUs, 471 chimeras

## Combine the rep sets between de novo and reference-based OTU picking
```
cat mergedfastq/closed_reference.fasta mergedfastq/denovo_otus.fasta > mergedfastq/full_rep_set.fna
```

## Map rep_set back to pre-dereplicated sequences and make OTU tables
```
./usearch64 -usearch_global mergedfastq/merged.fq -db mergedfastq/full_rep_set.fna  -strand plus -id 0.97 -uc OTU_map.uc -otutabout OTU_table.txt -biomout OTU_jsn.biom
```
outputs here = OTU table and OTU_jsn.biom -> for goin in qiime




# Part II: Switch to QIIME

## Assign taxonomy to GreenGenes v 13.8 and UCLUST
```
assign_taxonomy.py -i full_rep_set.fna -o taxonomy -r /mnt/home/kearnspa/gg_13_8_otus/rep_set/97_otus.fasta -t /mnt/home/kearnspa/gg_13_8_otus/taxonomy/97_otu_taxonomy.txt
#-r reference -> path to silva db here (Silva_119_rep_set97.fna)
# -t taxonomy
```

## Add taxonomy to OTU table
```
biom add-metadata -i OTU_jsn.biom -o otu_table_tax.biom --observation-metadata-fp=taxonomy/full_rep_set_tax_assignments.txt --sc-separated=taxonomy --observation-header=OTUID,taxonomy
```

## Filter non-bacteria/archaea
```
filter_taxa_from_otu_table.py -i otu_table_tax.biom -o otu_table_tax_filt.biom -n o__Streptophyta,o__Chlorophyta,f__mitochondria,Unassigned
```

## Align sequences to GreenGenes with PyNast
```
align_seqs.py -i full_rep_set.fna -o alignment -t /mnt/home/kearnspa/gg_13_8_otus/rep_set_aligned/97_otus.fasta
```

## Filter excess gaps from alignment
```
filter_alignment.py -i alignment/full_rep_set_aligned.fasta -o alignment/filtered_alignment
```

## Make phylogeny with fasttree
```
make_phylogeny.py -i alignment/filtered_alignment/full_rep_set_aligned_pfiltered.fasta -o rep_set.tre
```

## Summarize the OTU table and rarefy OTU table to lowest sequencing depth
```
biom summarize-table -i otu_table_tax_filt.biom -o otu_table_summary.txt

#this sample is low at 169 sequences: 062615Wet1D. FIlter it

filter_samples_from_otu_table.py -i otu_table_tax_filt.biom -o otu_table_tax_filt2.biom -n 10000

single_rarefaction.py -d 16618 -o single_rare.biom -i otu_table_tax_filt2.biom
```

## Calculate alpha and beta diversity
```
beta_diversity.py -m bray_curtis,unweighted_unifrac,weighted_unifrac -i single_rare.biom -o beta_div -t rep_set.tre

alpha_diversity.py -m PD_whole_tree,shannon -i single_rare.biom -o alpha -t rep_set.tre
```

## Summarize taxonomy data
```
summarize_taxa.py -i otu_table_tax_filt.biom -o taxa_sum
```
